{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "id": "HMEE9-tzo33x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import torch\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow  # for Colab display\n",
        "\n",
        "# 1. Paths & Parameters\n",
        "input_video   = \"/content/How to play the Cover Drive - Cover Drive Technique and Tips.mp4\"\n",
        "output_video  = \"/content/Output/output_video.mp4\"\n",
        "conf_threshold = 0.5\n",
        "\n",
        "os.makedirs(os.path.dirname(output_video), exist_ok=True)\n",
        "\n",
        "# 2. Device Check\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Running on {device.upper()}\")\n",
        "\n",
        "# 3. Load Models\n",
        "pose_model = YOLO(\"/content/yolo11x-pose.pt\").to(device)\n",
        "obj_model  = YOLO(\"/content/yolo12x.pt\").to(device)\n",
        "\n",
        "# 4. Keypoint Colors (Body Joints Only: COCO Indices 5 to 16)\n",
        "keypoint_colors = [\n",
        "    (0, 255, 255),  # 0: Left Shoulder\n",
        "    (128, 0, 128),  # 1: Right Shoulder\n",
        "    (255, 128, 0),  # 2: Left Elbow\n",
        "    (0, 128, 255),  # 3: Right Elbow\n",
        "    (128, 255, 0),  # 4: Left Wrist\n",
        "    (255, 0, 128),  # 5: Right Wrist\n",
        "    (0, 128, 0),    # 6: Left Hip\n",
        "    (128, 0, 0),    # 7: Right Hip\n",
        "    (0, 255, 128),  # 8: Left Knee\n",
        "    (128, 128, 0),  # 9: Right Knee\n",
        "    (0, 0, 128),    # 10: Left Ankle\n",
        "    (128, 128, 255) # 11: Right Ankle\n",
        "]\n",
        "\n",
        "# 5. Define Skeleton Connections (Based on Body Keypoints)\n",
        "connections = [\n",
        "    (0, 1),      # Left Shoulder to Right Shoulder\n",
        "    (0, 2),      # Left Shoulder to Left Elbow\n",
        "    (2, 4),      # Left Elbow to Left Wrist\n",
        "    (1, 3),      # Right Shoulder to Right Elbow\n",
        "    (3, 5),      # Right Elbow to Right Wrist\n",
        "    (6, 8),      # Left Hip to Left Knee\n",
        "    (8, 10),     # Left Knee to Left Ankle\n",
        "    (7, 9),      # Right Hip to Right Knee\n",
        "    (9, 11),     # Right Knee to Right Ankle\n",
        "    (0, 6),      # Left Shoulder to Left Hip\n",
        "    (1, 7),      # Right Shoulder to Right Hip\n",
        "    (6, 7)       # Left Hip to Right Hip\n",
        "]\n",
        "\n",
        "# 6. Open Video & Setup Writer\n",
        "cap = cv2.VideoCapture(input_video)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Error: cannot open video file.\")\n",
        "\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Compute frame sampling to process 6 frames per second\n",
        "skip_frames = max(1, int(fps / 6))\n",
        "print(f\"Original FPS: {fps}, Processing every {skip_frames}th frame to achieve ~6 FPS\")\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out    = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
        "\n",
        "# 7. Processing Loop\n",
        "frame_idx     = 0\n",
        "processed_cnt = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Process only every nth frame to achieve 6 FPS\n",
        "    if frame_idx % skip_frames != 0:\n",
        "        frame_idx += 1\n",
        "        continue\n",
        "\n",
        "    # Object Tracking (Bat and Ball)\n",
        "    obj_results = obj_model.track(frame, persist=True)\n",
        "\n",
        "    # Pose Estimation\n",
        "    pose_results = pose_model(frame)\n",
        "\n",
        "    # Draw Pose Keypoints & Skeleton\n",
        "    kpts = pose_results[0].keypoints.data\n",
        "    if kpts is not None:\n",
        "        for person in kpts:  # Each person detected\n",
        "            # Extract only body keypoints (COCO indices 5 to 16)\n",
        "            if len(person) >= 17:\n",
        "                body_kpts = person[5:17]\n",
        "            else:\n",
        "                continue  # Skip if keypoints are incomplete\n",
        "\n",
        "            # Draw Keypoints\n",
        "            for idx, point in enumerate(body_kpts):\n",
        "                if len(point) == 3:\n",
        "                    x, y, conf = point\n",
        "                else:\n",
        "                    x, y, conf = point[0], point[1], 1.0\n",
        "                if conf >= conf_threshold:\n",
        "                    color = keypoint_colors[idx]\n",
        "                    cv2.circle(frame, (int(x), int(y)), 5, color, -1)\n",
        "\n",
        "            # Draw Skeleton Lines\n",
        "            for pt1, pt2 in connections:\n",
        "                p1 = body_kpts[pt1]\n",
        "                p2 = body_kpts[pt2]\n",
        "                if len(p1) == 3:\n",
        "                    x1, y1, c1 = p1\n",
        "                else:\n",
        "                    x1, y1, c1 = p1[0], p1[1], 1.0\n",
        "                if len(p2) == 3:\n",
        "                    x2, y2, c2 = p2\n",
        "                else:\n",
        "                    x2, y2, c2 = p2[0], p2[1], 1.0\n",
        "                if c1 >= conf_threshold and c2 >= conf_threshold:\n",
        "                    line_color = keypoint_colors[pt1]\n",
        "                    cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), line_color, 2)\n",
        "\n",
        "    # Draw Bat & Ball Detections\n",
        "    for box in obj_results[0].boxes:\n",
        "        cls_id = int(box.cls)\n",
        "        if cls_id == 34 or cls_id == 32:  # 34: bat, 32: ball\n",
        "            x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
        "            if cls_id == 34:\n",
        "                color, label = (255, 0, 0), \"bat\"  # Blue for bat\n",
        "            else:\n",
        "                color, label = (0, 255, 255), \"ball\"  # Yellow for ball\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    # Write & Display\n",
        "    out.write(frame)\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    processed_cnt += 1\n",
        "    if processed_cnt % 100 == 0:\n",
        "        print(f\"Processed {processed_cnt} frames.\")\n",
        "\n",
        "    frame_idx += 1\n",
        "\n",
        "# 8. Cleanup\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(f\"Processing complete. Output saved to {output_video}\")"
      ],
      "metadata": {
        "id": "ldxAkaLQo8lI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Music Transcription with Transformers",
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}